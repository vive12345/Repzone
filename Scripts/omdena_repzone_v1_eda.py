# -*- coding: utf-8 -*-
"""Omdena_Repzone_v1_EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UKEC3vwyevONtj6qvabruGrtHZ3blP3p

# EDA on the data provided by the client
-------------------------------------------------------------
**Date:** 11th March 2025

**Written By:** N Priyanka

**Description:**

* Dataset: Omdena_Repzone_v1.xlsx

Exploratory data analysis on the dataset.
It has three sheets: 1) Representative 2) Customer and 3) Route.

In this notebook, we perform the EDA on the first two data.

**Columns in Representative table:**
RepresentativeId,
DailyMinCustomerCount,
DailyMaxCustomerCount,
WorkStartTime(hh:mm),
WorkEndTime(hh:mm),
WorkingDays,
NoonBreakDuration (hh:mm),
BreakTimeBeforeNoon(hh:mm),
BreakTimeAfterNoon(hh:mm)

**Columns in Customers table:**

CustomerId,
VisitDuration,
"VisitFreq,(1: Every Week, 2: Every 2 Weeks, 3: Everey 3 Weeks, 4: Every 4 Weeks)",
MustVisitDays,
EligibilityBeginTime (hh:mm),
EligibilityEndTime (hh:mm),
Country	City,
District,
AddressText,
Latitude,
Longitude

**This notebook is divided into 5 sections**:
1. Perform EDA on Representative data.
2. Perform EDA on Customer data.
3. Visualization of customer locations using Folium.
4. Cross dataset analysis.
5. Geocoding for finding the coordinates for missing addresses.

_____________________________________________________________
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import folium
from folium.plugins import HeatMap

# Load datasets
rep_df = pd.read_excel("/content/drive/MyDrive/Repzone/Omdena_Repzone_v1.xlsx", sheet_name='Representative')
customers_df = pd.read_excel("/content/drive/MyDrive/Repzone/Omdena_Repzone_v1.xlsx", sheet_name='Customer')

rep_df.to_csv("/content/drive/MyDrive/Repzone/Representatives.csv", index=False)
customers_df.to_csv("/content/drive/MyDrive/Repzone/Customers.csv", index=False)

df = pd.read_csv("/content/drive/MyDrive/Repzone/Customers.csv")
df.head(2)

"""# ----- REPRESENTATIVES EDA -----"""

rep_df.info()

#Basic Statistics
print("REPRESENTATIVES SUMMARY")
print(f"Total representatives: {rep_df.shape[0]}")
print("\nBasic statistics for customer count capacity:")
print(rep_df[['DailyMinCustomerCount', 'DailyMaxCustomerCount']].describe())
print(rep_df.info)

# Convert time strings to datetime objects for easier manipulation
def time_str_to_minutes(time_str):
    """Convert time string (HH:MM) to minutes since midnight"""
    hours, minutes = map(int, time_str.split(':'))
    return hours * 60 + minutes

"""##Feature engineering on the data

"""

# Process time data
rep_df['WorkStartMinutes'] = rep_df['WorkStartTime(hh:mm)'].apply(time_str_to_minutes)
rep_df['WorkEndMinutes'] = rep_df['WorkEndTime(hh:mm)'].apply(time_str_to_minutes)
rep_df['NoonBreakMinutes'] = rep_df['NoonBreakDuration (hh:mm)'].apply(time_str_to_minutes)
rep_df['BreakBeforeNoonMinutes'] = rep_df['BreakTimeBeforeNoon(hh:mm)'].apply(time_str_to_minutes)
rep_df['BreakAfterNoonMinutes'] = rep_df['BreakTimeAfterNoon(hh:mm)'].apply(time_str_to_minutes)

# Calculate total working minutes per day (excluding breaks)
rep_df['TotalWorkMinutes'] = (
    rep_df['WorkEndMinutes'] - rep_df['WorkStartMinutes'] -
    rep_df['NoonBreakMinutes'] - rep_df['BreakBeforeNoonMinutes'] -
    rep_df['BreakAfterNoonMinutes']
)

# Convert to hours for better readability
rep_df['TotalWorkHours'] = rep_df['TotalWorkMinutes'] / 60
print("\nWorking hours statistics:")
print(rep_df['TotalWorkHours'].describe())

rep_df.info()

rep_df['WorkingDays'].unique()

# Analyze working days

rep_df['WorkingDaysCount'] = rep_df['WorkingDays'].apply(lambda x: len(x.split(',')))

print("\nWorking days distribution:")
print(rep_df['WorkingDaysCount'].value_counts().sort_index())

rep_df['DailyMinCustomerCount'].unique()

rep_df['DailyMaxCustomerCount'].unique()

(rep_df['WorkStartMinutes'] / 60).unique()

(rep_df['WorkEndMinutes'] / 60).unique()

# Visualize key distributions
plt.figure(figsize=(15, 10))

# Customer capacity plot
plt.subplot(2, 2, 1)
plt.hist(rep_df['DailyMinCustomerCount'], alpha=0.5, label='Min Customers')
plt.hist(rep_df['DailyMaxCustomerCount'], alpha=0.5, label='Max Customers')
plt.legend()
plt.title('Daily Customer Capacity Distribution')
plt.xlabel('Number of Customers')
plt.ylabel('Count of Representatives')
plt.grid("ON")

# Working hours distribution
plt.subplot(2, 2, 2)
plt.hist(rep_df['TotalWorkHours'], bins=10)
plt.title('Distribution of Daily Working Hours')
plt.xlabel('Hours')
plt.ylabel('Count of Representatives')
plt.grid("ON")

# Start time distribution
plt.subplot(2, 2, 3)
sns.histplot(rep_df['WorkStartMinutes'] / 60, bins=24)
plt.title('Distribution of Work Start Time')
plt.xlabel('Hour of Day')
plt.ylabel('Count of Representatives')
plt.grid("ON")

# End time distribution
plt.subplot(2, 2, 4)
sns.histplot(rep_df['WorkEndMinutes'] / 60, bins=24)
plt.title('Distribution of Work End Time')
plt.xlabel('Hour of Day')
plt.ylabel('Count of Representatives')

plt.tight_layout()
plt.grid("ON")
plt.show()

# Set figure size
plt.figure(figsize=(15, 10))

# 1. Customer Count Capacity - Bar Chart for Min and Max Customers
plt.subplot(2, 2, 1)
min_customer_count = 1  # Minimum customer count
max_customer_count = 15  # Maximum customer count
labels = ['Min Customers', 'Max Customers']
sizes = [len(rep_df[rep_df['DailyMinCustomerCount'] == min_customer_count]),
         len(rep_df[rep_df['DailyMaxCustomerCount'] == max_customer_count])]
plt.bar(labels, sizes, color=['#66b3ff', '#99ff99'])
plt.title('Customer Capacity Distribution')
plt.xlabel('Customer Capacity')
plt.ylabel('Number of Representatives')
plt.grid(True)

# 2. Working Hours - Constant Line for Daily Work Hours (7.5 hours)
plt.subplot(2, 2, 2)
plt.axhline(7.5, color='lightcoral', linestyle='-', label="Working Hours (7.5 hrs)")
plt.title('Working Hours per Representative (Constant)')
plt.xlabel('Representatives')
plt.ylabel('Working Hours')
plt.legend()
plt.grid(True)

# 3. Working Days and Schedule - Display consistency for 6 days of the week
plt.subplot(2, 2, 3)
days_of_week = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']
representative_count = len(rep_df)  # All reps have the same schedule
plt.bar(days_of_week, [representative_count] * 6, color='lightgreen')
plt.title('Working Days per Representative')
plt.xlabel('Day of the Week')
plt.ylabel('Number of Representatives')
plt.grid(True)

# 4. Visualize Start Time- Bar plot of start time
plt.subplot(2, 2, 4)
# Assuming the work start times are consistent for all reps
start_time_hours = rep_df['WorkStartMinutes'] / 60  # Assuming WorkStartMinutes is available in data
sns.histplot(start_time_hours, bins=24, kde=False, color='royalblue', stat='count')
plt.title('Work Start Time (Consistent Across Representatives)')
plt.xlabel('Start Time (Hour of Day)')
plt.ylabel('Count of Representatives')
plt.grid(True)

# Adjust layout
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 5))
sns.countplot(x=rep_df['DailyMinCustomerCount'], palette="Blues", label='Min Customers')
sns.countplot(x=rep_df['DailyMaxCustomerCount'], palette="Reds", label='Max Customers', alpha=0.6)
plt.xlabel("Number of Customers")
plt.ylabel("Count")
plt.title("Distribution of Daily Min and Max Customers")
plt.legend()
plt.show()

"""# ----- CUSTOMERS EDA -----"""

print("\n\nCUSTOMERS SUMMARY")
print(f"Total customers: {customers_df.shape[0]}")

# Visit duration statistics
print("\nVisit duration statistics (minutes):")
print(customers_df['VisitDuration'].describe())

customers_df.columns

customers_df.info()

customers_df.isnull().sum()

"""## We will use the below dataframe for performing geocoding at the end of the notebook."""

customers_with_missing_coordinates = customers_df.loc[np.where(customers_df['Latitude'].isna())][['Country','City','District','AddressText']]

l_cols_concat = ['City','District','Country']

# Composing the Full address by concatenating the columns mentioned in the above list l_cols_concat
customers_with_missing_coordinates['Full_Address'] = customers_with_missing_coordinates['AddressText'].str.cat(others=customers_with_missing_coordinates[l_cols_concat], sep=',',na_rep='')

"""##Continuing with the EDA on customers_df"""

customers_df['MustVisitDays'].value_counts()

customers_df['VisitFreq \n(1: Every Week, \n2: Every 2 Weeks, \n3: Everey 3 Weeks, \n4: Every 4 Weeks)']

customers_df.rename(columns={'VisitFreq \n(1: Every Week, \n2: Every 2 Weeks, \n3: Everey 3 Weeks, \n4: Every 4 Weeks)': 'VisitFreq'}, inplace=True)

customers_df['VisitFreq'].value_counts()

# Visit frequency breakdown
print("\nVisit frequency distribution:")
freq_mapping = {1: "Weekly", 2: "Bi-weekly", 3: "Every 3 weeks", 4: "Monthly"}
customers_df['VisitFreqDescription'] = customers_df['VisitFreq'].map(freq_mapping)
print(customers_df['VisitFreqDescription'].value_counts())

"""## Feature engineering on the dataset."""

# Process customer time windows
customers_df['EligibilityBeginMinutes'] = customers_df['EligibilityBeginTime (hh:mm)'].apply(time_str_to_minutes)
customers_df['EligibilityEndMinutes'] = customers_df['EligibilityEndTime (hh:mm)'].apply(time_str_to_minutes)
customers_df['EligibilityWindowMinutes'] = customers_df['EligibilityEndMinutes'] - customers_df['EligibilityBeginMinutes']
customers_df['EligibilityWindowHours'] = customers_df['EligibilityWindowMinutes'] / 60

print("\nEligibility window statistics (hours):")
print(customers_df['EligibilityWindowHours'].describe())

# Geographic distribution
print("\nCustomers by country:")
print(customers_df['Country'].value_counts())

print("\nTop 10 cities by customer count:")
print(customers_df['City'].value_counts().head(10))

customers_df['City'].value_counts().head(10).plot(kind='bar', title="Top 10 cities by customer count", grid=True)

customers_df['EligibilityWindowHours'].unique()

customers_df.loc[np.where(customers_df['EligibilityWindowHours']==3.5)]

customers_df['EligibilityBeginMinutes'].unique()

# Create visualizations for customers
plt.figure(figsize=(15, 10))

# Visit duration
plt.subplot(2, 2, 1)
plt.hist(customers_df['VisitDuration'], bins=15)
plt.title('Distribution of Visit Duration')
plt.xlabel('Duration (minutes)')
plt.ylabel('Count of Customers')

# Visit frequency
plt.subplot(2, 2, 2)
sns.countplot(y='VisitFreqDescription', data=customers_df)
plt.title('Visit Frequency Distribution')
plt.xlabel('Count of Customers')
plt.ylabel('Visit Frequency')

# Eligibility window
plt.subplot(2, 2, 3)
plt.hist(customers_df['EligibilityWindowHours'], bins=12)
plt.title('Distribution of Eligibility Window Size')
plt.xlabel('Hours')
plt.ylabel('Count of Customers')
plt.xlim([1, 10])

# Eligibility start time
plt.subplot(2, 2, 4)
sns.histplot(customers_df['EligibilityBeginMinutes'] / 60, bins=24)
plt.title('Distribution of Eligibility Start Time')
plt.xlabel('Hour of Day')
plt.ylabel('Count of Customers')

plt.tight_layout()
plt.show()

"""# ----- CROSS-DATASET ANALYSIS -----"""

rep_df.columns

customers_df.columns

# Analyze time window overlap between representatives and customers
# For demonstration, compare the average working hours to average eligibility hours

avg_rep_start = rep_df['WorkStartMinutes'].mean() / 60
avg_rep_end = rep_df['WorkEndMinutes'].mean() / 60
avg_cust_start = customers_df['EligibilityBeginMinutes'].mean() / 60
avg_cust_end = customers_df['EligibilityEndMinutes'].mean() / 60

print("\n----- CROSS-DATASET INSIGHTS -----")
print(f"Average representative working hours: {avg_rep_start:.2f} - {avg_rep_end:.2f}")
print(f"Average customer eligibility hours: {avg_cust_start:.2f} - {avg_cust_end:.2f}")

"""**total_weekly_rep_capacity:** This calculates the total weekly capacity of all representatives by:

1. Taking the sum of DailyMaxCustomerCount across all representatives - this gives the maximum number of customers that can be served per day by all representatives combined
2. Multiplying by the average number of working days per representative (WorkingDaysCount.mean())
3. The result is an estimate of how many customer visits the representatives can handle in a typical week.

**total_weekly_customer_demand:** This calculates the total weekly customer visit demand by:

Converting each customer's visit frequency into a weekly equivalent:

If VisitFreq = 1 (weekly visits), then WeeklyVisitEquivalent = 1.0 visits per week
If VisitFreq = 2 (bi-weekly visits), then WeeklyVisitEquivalent = 0.5 visits per week
If VisitFreq = 4 (monthly visits), then WeeklyVisitEquivalent = 0.25 visits per week


Summing these weekly equivalents to get the total number of customer visits needed per week.

**Capacity Utilization:** This calculates what percentage of your total capacity is being utilized:

Dividing the total weekly demand by the total weekly capacity
Multiplying by 100 to express it as a percentage.

The result tells you if your team is under-utilized (< 100%) or over-capacity (> 100%)
"""

# Calculate overall capacity vs demand (simplified)
total_weekly_rep_capacity = (
    rep_df['DailyMaxCustomerCount'].sum() *
    rep_df['WorkingDaysCount'].mean()
)

# Calculate total weekly customer visits needed
customers_df['WeeklyVisitEquivalent'] = 1 / customers_df['VisitFreq']
total_weekly_customer_demand = customers_df['WeeklyVisitEquivalent'].sum()

print(f"\nEstimated weekly capacity (max customers): {total_weekly_rep_capacity:.2f}")
print(f"Estimated weekly demand (customer visits): {total_weekly_customer_demand:.2f}")
print(f"Capacity utilization: {(total_weekly_customer_demand / total_weekly_rep_capacity * 100):.2f}%")

# Final plots for cross-dataset insights
plt.figure(figsize=(12, 6))

# Time window comparison
plt.subplot(1, 2, 1)
plt.barh(y=0, width=avg_rep_end - avg_rep_start, left=avg_rep_start, height=0.3, label='Rep Avg Hours', color='blue')
plt.barh(y=1, width=avg_cust_end - avg_cust_start, left=avg_cust_start, height=0.3, label='Customer Avg Hours', color='green')
plt.yticks([0, 1], ['Representatives', 'Customers'])
plt.xlabel('Hour of Day')
plt.title('Average Working vs. Eligibility Hours')
plt.legend()
plt.xlim(0, 24)
plt.grid(axis='x')

# Capacity vs Demand
plt.subplot(1, 2, 2)
plt.bar(['Capacity', 'Demand'], [total_weekly_rep_capacity, total_weekly_customer_demand])
plt.title('Weekly Capacity vs. Demand')
plt.ylabel('Number of Visits')

plt.tight_layout()
plt.show()

"""# ----- MAP VISUALIZATION USING FOLIUM -----"""

def convert_coordinates(df):
    """
    Converts 'Longitude' and 'Latitude' columns to numeric, handling comma as decimal if the dtype is not float.
    """
    cols_to_check = ['Longitude', 'Latitude']
    for col in cols_to_check:
        if col in df.columns and df[col].dtype != float:
            # Check if there are any non-numeric values containing comma
            non_numeric_with_comma = df[pd.to_numeric(df[col], errors='coerce').isna()][col].astype(str).str.contains(',').any()
            if non_numeric_with_comma:
                df[col] = df[col].str.replace(',', '.', regex=False)
            df[col] = pd.to_numeric(df[col], errors='coerce')
    return df

customers_df = convert_coordinates(customers_df)

customers_df[['Latitude','Longitude']][:5]

customers_df.isnull().sum()

# Option 1: Remove records with missing coordinates (only for EDA visualization)
customers_with_coords = customers_df.dropna(subset=['Latitude', 'Longitude'])
print(f"\nCustomers with valid coordinates: {len(customers_with_coords)}")

"""**Note: Here we dropped the rows with missing coordinates.**"""

# Create a map centered on the average position
map_center = [customers_with_coords['Latitude'].mean(), customers_with_coords['Longitude'].mean()]
customer_map = folium.Map(location=map_center, zoom_start=10)

# Add a heatmap layer
heat_data = customers_with_coords[['Latitude', 'Longitude']].values.tolist()
HeatMap(heat_data).add_to(customer_map)

# Add markers for each customer
for idx, row in customers_with_coords.iterrows():
    popup_text = f"""
    Customer ID: {row['CustomerId']}<br>
    Visit Duration: {row['VisitDuration']} mins<br>
    Visit Frequency: {row['VisitFreqDescription']}<br>
    Address: {row['AddressText']}, {row['District']}, {row['City']}, {row['Country']}
    """
    folium.Marker(
        location=[row['Latitude'], row['Longitude']],
        popup=folium.Popup(popup_text, max_width=300),
        icon=folium.Icon(color='blue', icon='info-sign')
    ).add_to(customer_map)

# Save the map
customer_map.save('customer_locations.html')

"""#---------Geocoding for missing geospatial coordinates--------

##--------Geocoding using OpenStreetMap API------------------
Geocoding the missing addresses using OpenStreetMap API.
Result: Not successful
"""

! pip install geopy --q

import geopy
from geopy.extra.rate_limiter import RateLimiter
from tqdm.notebook import tqdm
from geopy.geocoders import Nominatim

tqdm.pandas()

locator = Nominatim(user_agent='solveTSP', timeout=10)
geocode = RateLimiter(locator.geocode, min_delay_seconds=1)

customers_with_missing_coordinates['location'] = customers_with_missing_coordinates['Full_Address'].progress_apply(geocode)
customers_with_missing_coordinates

"""##------------- Geocoding using ArcGIS API--------------
Result: Successful except for one location
"""

import pandas as pd
from tqdm.notebook import tqdm
from geopy.geocoders import ArcGIS
import time

# Initialize geolocator with a timeout of 10 seconds
geolocator_arcgis = ArcGIS(timeout=10)

# Lists to hold the coordinates
latitudes = []
longitudes = []

# Loop over the DataFrame and get coordinates
for address in tqdm(customers_with_missing_coordinates['Full_Address']):
    time.sleep(1)  # Add delay to avoid hitting rate limits
    try:
        location = geolocator_arcgis.geocode(address)
        if location:
            latitudes.append(location.latitude)  # Extract latitude
            longitudes.append(location.longitude)  # Extract longitude
            print(f"Processing {address}: Latitude: {location.latitude}, Longitude: {location.longitude}")
        else:
            latitudes.append(None)  # If location not found, append None
            longitudes.append(None)
            print(f"Address {address} not found.")
    except Exception as e:
        latitudes.append(None)  # Append None if an error occurs
        longitudes.append(None)
        print(f"Error processing {address}: {e}")

# Add the coordinates to the DataFrame
customers_with_missing_coordinates['Latitude'] = latitudes
customers_with_missing_coordinates['Longitude'] = longitudes

# Display the updated DataFrame
customers_with_missing_coordinates

customers_with_missing_coordinates.isnull().sum()

customers_with_missing_coordinates.loc[customers_with_missing_coordinates['Latitude'].isna()]

customers_with_missing_coordinates.to_csv("/content/drive/MyDrive/Repzone/address_geocoded.csv",index=True)