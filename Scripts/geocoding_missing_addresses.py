# -*- coding: utf-8 -*-
"""geocoding_missing_addresses.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dBdi1fhLows9915_067nWLaGTzHYR_qc
"""

!pip install geopy

import pandas as pd

# Load the Excel file
file_path = r"C:\Users\sachi\Downloads\Omdena_Repzone_v1.xlsx"

# Read all sheets into a dictionary of DataFrames
dfs = pd.read_excel(file_path, sheet_name=None)

# `dfs` is now a dictionary where the keys are sheet names and the values are DataFrames
for sheet_name, df in dfs.items():
    print(f"Sheet name: {sheet_name}")
    print(df.head())  # Display the first few rows of each sheet

dfs['Customer']['VisitFreq \n(1: Every Week, \n2: Every 2 Weeks, \n3: Everey 3 Weeks, \n4: Every 4 Weeks)'].value_counts()

dfs['Customer'].columns

dfs['Customer'].describe()



df.isna().sum()





location_subset = df[df['Latitude'].isna() & df['Longitude'].isna()][['Country', 'City', 'District', 'AddressText']]

# Reset index for cleaner output
location_subset = location_subset.reset_index(drop=True)

# Display the result
print(location_subset)

location_subset['FullAddress'] = location_subset.apply(lambda row: f"{row['AddressText']}, {row['District']}, {row['City']}, {row['Country']}", axis=1)

# Save to a .txt file (each line contains a complete address)
file_path = "missing_addresses.txt"
location_subset['FullAddress'].to_csv(file_path, index=False, header=False, sep='\n', mode='w', encoding='utf-8')

print(f"File saved: {file_path}")

!pip install webdriver-manager

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

# Automatically download and install the correct ChromeDriver version
chrome_driver_path = ChromeDriverManager().install()

# Use the downloaded ChromeDriver
service = Service(chrome_driver_path)
driver = webdriver.Chrome(service=service)

# Test if Selenium is working
driver.get("https://www.google.com/")
print("ChromeDriver is working fine!")

# Close the browser
driver.quit()

import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
import time

service = Service(chrome_driver_path)
driver = webdriver.Chrome(service=service)

# Load addresses from the file
file_path = "missing_addresses.txt"
with open(file_path, "r", encoding="utf-8") as f:
    addresses = f.read().splitlines()

# Create a DataFrame to store results
results = []

# Function to get latitude and longitude from Google Maps
def get_coordinates_from_google_maps(address):
    # Open Google Maps
    driver.get("https://www.google.com/maps")
    time.sleep(3)

    try:
        # Wait and find the search box
        search_box = driver.find_element(By.ID, "searchboxinput")

        # Use JavaScript to fully clear search box
        driver.execute_script("arguments[0].value = '';", search_box)
        time.sleep(1)  # Wait for clearing

        # Click search box, enter address, and search
        search_box.click()
        search_box.send_keys(address)
        time.sleep(1)  # Small delay
        search_box.send_keys(Keys.RETURN)

        # Wait for the page to load new results
        time.sleep(7)

        # Extract coordinates from the URL
        current_url = driver.current_url
        if "@" in current_url:  # Ensure URL contains coordinates
            parts = current_url.split("@")[1].split(",")[:2]
            latitude = parts[0]
            longitude = parts[1]
            return latitude, longitude
    except Exception as e:
        print(f"Error fetching coordinates for {address}: {e}")

    return None, None

# Process each address, get coordinates, and store results
for address in addresses:
    lat, lon = get_coordinates_from_google_maps(address)
    results.append({"Address": address, "Latitude": lat, "Longitude": lon})
    print(f"Processed: {address} -> Latitude: {lat}, Longitude: {lon}")

# Close the browser
driver.quit()

# Convert results to a DataFrame and save as CSV
df = pd.DataFrame(results)
df.to_csv("geocoded_addresses.csv", index=False, encoding="utf-8")

print("All addresses processed and saved to geocoded_addresses.csv!")

import pandas as pd
import folium

# Load the geocoded addresses from CSV
file_path = "geocoded_addresses.csv"
df = pd.read_csv(file_path)

# Create a map centered at the first coordinate
map_center = [df["Latitude"].mean(), df["Longitude"].mean()]  # Center map at the average location
mymap = folium.Map(location=map_center, zoom_start=6)

# Add markers for each address
for index, row in df.iterrows():
    folium.Marker(
        location=[row["Latitude"], row["Longitude"]],
        popup=row["Address"],  # Show address on click
        icon=folium.Icon(color="blue", icon="info-sign")
    ).add_to(mymap)

# Save the map to an HTML file
mymap.save("map.html")
print("Map saved as map.html! Open it in your browser to view.")



