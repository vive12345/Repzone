{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e88fd21-d551-4101-8281-425e4397ab95",
   "metadata": {},
   "source": [
    "# Omdena RepZone - Auxiliary Functions\n",
    "### Author: Hugo C Marrochio\n",
    "### Date: June 4th 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a729a3-83bf-46d5-aa73-9b9114e48d3a",
   "metadata": {},
   "source": [
    "run on terminal \n",
    "\n",
    "jupyter nbconvert --to script auxiliary_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94631085-2563-4cee-bc3e-50aa5954206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import KMeans\n",
    "from pyproj import Proj, Transformer\n",
    "import folium\n",
    "from kneed import KneeLocator\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from pyproj import Transformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "from ortools.constraint_solver import pywrapcp, routing_enums_pb2\n",
    "\n",
    "from folium.plugins import MarkerCluster\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "from folium import Map, FeatureGroup, PolyLine, Marker, CircleMarker, Icon, LayerControl\n",
    "from branca.element import Template, MacroElement\n",
    "import polyline\n",
    "\n",
    "\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bdc954-7865-479e-9de7-aebd5b37ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example RepZone offices and their coordinates, will definy it globally since many functions use it.\n",
    "repzone_offices = {\n",
    "    \"Istanbul\": [40.9923, 29.0800],\n",
    "    \"Adana\": [37.0015, 35.3213],\n",
    "    \"Ankara\": [39.9334, 32.8597],\n",
    "    \"Izmir\": [38.4707, 27.1417],\n",
    "    \"TekirdaÄŸ\": [41.1872, 27.8833]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de15ba-7bbc-4347-bc66-667222b302e3",
   "metadata": {},
   "source": [
    "## Part 1 - Geographical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759abd9-7fe2-46ef-9559-0f7c3f5b9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_kmeans_clustering(\n",
    "    df,\n",
    "    lat_col='Latitude',\n",
    "    lon_col='Longitude',\n",
    "    min_size=30,\n",
    "    max_size=300,\n",
    "    initial_k=10,\n",
    "    random_state=42,\n",
    "):\n",
    "    '''\n",
    "    Function to calculate clusters given parameters to determine maximum and minimum sizes, using KNN.\n",
    "\n",
    "    Input:\n",
    "    -----\n",
    "    df: DataFrame with geographic data to cluster.\n",
    "    \n",
    "    lat_col: Key for latitude, default is 'Latitude'\n",
    "    \n",
    "    lon_col: Key for longitude, default is 'Longitude'\n",
    "    \n",
    "    min_size: Default size is 30.\n",
    "    \n",
    "    max_size: Default size is 300.\n",
    "    \n",
    "    initial_k: Default is 10.\n",
    "\n",
    "    Output:\n",
    "    ------\n",
    "\n",
    "    df with cluster column\n",
    "    '''\n",
    "    \n",
    "    # Step 1: Project coordinates to UTM coordinates\n",
    "    \n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32633\", always_xy=True)\n",
    "    utm_coords = np.array([\n",
    "        transformer.transform(lon, lat) for lat, lon in zip(df[lat_col], df[lon_col])\n",
    "    ])\n",
    "    df = df.copy()\n",
    "    df['x'] = utm_coords[:, 0]\n",
    "    df['y'] = utm_coords[:, 1]\n",
    "\n",
    "    # Step 2: Initial KMeans, assuming initial_k number of clusters\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=initial_k, random_state=random_state).fit(utm_coords)\n",
    "    df['cluster'] = kmeans.labels_\n",
    "\n",
    "    # Step 3: Refine clusters to enforce min/max size\n",
    "    next_cluster_id = df['cluster'].max() + 1\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        cluster_sizes = df['cluster'].value_counts().to_dict()\n",
    "\n",
    "        for cluster_id, size in cluster_sizes.items():\n",
    "            subset = df[df['cluster'] == cluster_id]\n",
    "            if size > max_size:\n",
    "                # Split large cluster into subclusters\n",
    "                n_subclusters = int(np.ceil(size / max_size))\n",
    "                sub_kmeans = KMeans(n_clusters=n_subclusters, random_state=random_state)\n",
    "                sub_labels = sub_kmeans.fit_predict(subset[['x', 'y']])\n",
    "                for i, new_label in enumerate(sub_labels):\n",
    "                    df.loc[subset.index[i], 'cluster'] = next_cluster_id + new_label\n",
    "                next_cluster_id += n_subclusters\n",
    "                changed = True\n",
    "\n",
    "            elif size < min_size:\n",
    "                # Merge small cluster to closest centroid\n",
    "                subset_coords = subset[['x', 'y']].mean().values\n",
    "                # Compute distances to other centroids\n",
    "                other_clusters = df['cluster'].unique()\n",
    "                dists = []\n",
    "                for other_id in other_clusters:\n",
    "                    if other_id == cluster_id:\n",
    "                        continue\n",
    "                    other_coords = df[df['cluster'] == other_id][['x', 'y']].mean().values\n",
    "                    dist = np.linalg.norm(subset_coords - other_coords)\n",
    "                    dists.append((other_id, dist))\n",
    "                if dists:\n",
    "                    closest_id = min(dists, key=lambda x: x[1])[0]\n",
    "                    df.loc[df['cluster'] == cluster_id, 'cluster'] = closest_id\n",
    "                    changed = True\n",
    "\n",
    "    return df.drop(columns=['x', 'y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b15f77c-8fd9-4f42-83cf-e0a96dfb29b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_select_k(inertias, k_range):\n",
    "    ks = list(range(*k_range))\n",
    "    kl = KneeLocator(ks, inertias, curve=\"convex\", direction=\"decreasing\")\n",
    "    return kl.elbow\n",
    "\n",
    "def calculate_inertias(utm_coords, k_range=(5, 30)):\n",
    "    inertias = []\n",
    "    ks = range(*k_range)\n",
    "    for k in ks:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42).fit(utm_coords)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "    return inertias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355cfba2-d850-4b58-baa4-8bd5c1303af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_too_far(row, repzones, threshold_km=500):\n",
    "    client_coord = (row['Longitude'], row['Latitude'])\n",
    "    distances = [haversine(client_coord, office, unit=Unit.KILOMETERS) for office in repzones]\n",
    "    return all(d > threshold_km for d in distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f01a0-44c3-4033-8dbd-96ffd8533024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the closest RepZone office based on the distance\n",
    "def get_closest_repzone(client_lat, client_lon):\n",
    "    distances = {}\n",
    "    for office, coords in repzone_offices.items():\n",
    "        dist = geodesic((client_lat, client_lon), tuple(coords)).km  # distance in km\n",
    "        distances[office] = dist\n",
    "    closest_office = min(distances, key=distances.get)\n",
    "    return closest_office\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb3645e-02e0-4415-9ac0-3b3e24e1a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_weekly_schedule(df, num_weeks=4, random_state=42):\n",
    "    \"\"\"\n",
    "    For each cluster, distribute weekly and monthly clients across a 4-week horizon.\n",
    "    Weekly clients appear in all weeks; monthly clients are evenly split.\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    df: DataFrame\n",
    "    num_weeks: The future horizon planning, default is 4.\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    \n",
    "    Returns a new DataFrame with a `week` column.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    all_weeks = []\n",
    "\n",
    "    for cluster_id in df['cluster'].unique():\n",
    "        cluster_df = df[df['cluster'] == cluster_id]\n",
    "\n",
    "        # Weekly = 1, Monthly = 4\n",
    "        weekly_clients = cluster_df[cluster_df['VisitFreq'] == 1]\n",
    "        monthly_clients = cluster_df[cluster_df['VisitFreq'] == 4]\n",
    "\n",
    "        # Shuffle monthly clients and split them into chunks for each week\n",
    "        monthly_split = np.array_split(\n",
    "            monthly_clients.sample(frac=1, random_state=random_state),\n",
    "            num_weeks\n",
    "        )\n",
    "\n",
    "        for week in range(1, num_weeks + 1):\n",
    "            weekly_part = weekly_clients.copy()\n",
    "            weekly_part['week'] = week\n",
    "\n",
    "            monthly_part = monthly_split[week - 1].copy()\n",
    "            monthly_part['week'] = week\n",
    "\n",
    "            combined = pd.concat([weekly_part, monthly_part], ignore_index=True)\n",
    "            combined['cluster'] = cluster_id\n",
    "            all_weeks.append(combined)\n",
    "\n",
    "    return pd.concat(all_weeks).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c1450-550b-46d7-995b-52ddb267a744",
   "metadata": {},
   "source": [
    "## Part 2 - OpenRouteService, distance and duration matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ae9744-beb4-467d-a3a8-f54f03e5868a",
   "metadata": {},
   "source": [
    "#### Important that we are running a local docker container with Open Route Service; modify function accordingly with localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd9c74-b36c-41d8-bd9a-8bc241754368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ors_duration_distance(origins, destinations):\n",
    "    '''\n",
    "    Calculate the distance and travel duration matrices, \n",
    "    using local calculation on Open Route Service.\n",
    "\n",
    "    '''\n",
    "    ORS_MATRIX_URL = \"http://localhost:8084/ors/v2/matrix/driving-car\"\n",
    "\n",
    "    locations = [[lon, lat] for lat, lon in origins + destinations]\n",
    "    body = {\n",
    "        \"locations\": locations,\n",
    "        \"metrics\": [\"duration\", \"distance\"],\n",
    "        \"sources\": list(range(len(origins))),\n",
    "        \"destinations\": list(range(len(origins), len(destinations) + len(origins))),\n",
    "    }\n",
    "\n",
    "    response = requests.post(ORS_MATRIX_URL, json=body)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        durations = np.array(data[\"durations\"]) / 60\n",
    "        distances = np.array(data[\"distances\"]) / 1000\n",
    "        return durations.astype(int), distances\n",
    "    else:\n",
    "        print(\"ORS request failed:\", response.text)\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd63969-694f-4ff0-9e60-3ff360a4247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_matrices(df_schedule,df_centroids, batch_size=50, sleep_time=0.5):\n",
    "    \"\"\"\n",
    "    Computes distance and duration matrices for one cluster over 4 weeks.\n",
    "    Includes RepZone as the origin depot (index 0).\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "\n",
    "    df_schedule: DataFrame with geographic cluster and weekly schedule assigned.\n",
    "\n",
    "    batch_size: Default 50.\n",
    "\n",
    "    sleep_time: Default 0.5\n",
    "\n",
    "\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    \n",
    "    duration_matrices: {(cluster_id,week): np.array}\n",
    "    \n",
    "    distance_matrices: {(cluster_id,week): np.array}\n",
    "    \n",
    "    index_to_customer_id: {(cluster_id,week): list}\n",
    "    \"\"\"\n",
    "    \n",
    "    duration_matrices = {}\n",
    "    distance_matrices = {}\n",
    "    index_to_customer_id = {}\n",
    "\n",
    "    # cluster_lists=[2,7]\n",
    "\n",
    "    cluster_lists=df_schedule['cluster'].unique().tolist()\n",
    "    \n",
    "    for cluster_id in cluster_lists:\n",
    "\n",
    "        cluster_df = df_schedule[df_schedule['cluster'] == cluster_id]\n",
    "\n",
    "        # Find out the office assigned to the cluster we want to analyze\n",
    "        RepZone_test=df_centroids[df_centroids['cluster']==cluster_id]['Assigned_RepZone'].tolist()\n",
    "        \n",
    "        # Find the (Lat, Lon) coordinates of the office\n",
    "        RepZone_test_Lat_Lon=repzone_offices[RepZone_test[0]]\n",
    "        \n",
    "        # Invert to  (Lon, Lat)\n",
    "        RepZone = (RepZone_test_Lat_Lon[1], RepZone_test_Lat_Lon[0])   \n",
    "    \n",
    "        for week in sorted(cluster_df['week'].unique()):\n",
    "            week_df = cluster_df[cluster_df['week'] == week]\n",
    "    \n",
    "            client_coords = week_df[['Latitude', 'Longitude']].values\n",
    "            repzone_coords = (RepZone[1], RepZone[0])  # lon, lat â†’ lat, lon\n",
    "            all_coords = np.vstack([repzone_coords, client_coords])\n",
    "            n = len(all_coords)\n",
    "    \n",
    "            # Map index to CustomerId (0 is RepZone)\n",
    "            ids = ['RepZone'] + week_df['CustomerId'].tolist()\n",
    "            index_to_customer_id[(cluster_id,week)] = ids\n",
    "    \n",
    "            # Init matrices\n",
    "            durations = np.full((n, n), 99999, dtype=int)\n",
    "            distances = np.full((n, n), 9999, dtype=float)\n",
    "    \n",
    "            for i in range(0, n, batch_size):\n",
    "                batch_origins = all_coords[i:i + batch_size]\n",
    "    \n",
    "                for j in range(0, n, batch_size):\n",
    "                    batch_destinations = all_coords[j:j + batch_size]\n",
    "    \n",
    "                    dur, dist = get_ors_duration_distance(batch_origins.tolist(), batch_destinations.tolist())\n",
    "                    if dur is not None and dist is not None:\n",
    "                        durations[i:i + batch_size, j:j + batch_size] = dur\n",
    "                        distances[i:i + batch_size, j:j + batch_size] = dist\n",
    "    \n",
    "                sleep(sleep_time)\n",
    "    \n",
    "            np.fill_diagonal(durations, 2000)\n",
    "            np.fill_diagonal(distances, 0)\n",
    "    \n",
    "            duration_matrices[(cluster_id,week)] = durations\n",
    "            distance_matrices[(cluster_id,week)] = distances\n",
    "    \n",
    "            print(f\"Cluster {cluster_id} Week {week}: {n-1} clients\")\n",
    "\n",
    "    return duration_matrices, distance_matrices, index_to_customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948364d7-8c18-4c73-bb46-4e675e6e57bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_assigned_office(row):\n",
    "    centroid = (row[\"Latitude\"], row[\"Longitude\"])\n",
    "    office = tuple(repzone_offices[row[\"Assigned_RepZone\"]])\n",
    "    return geodesic(centroid, office).km"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb61653-f918-4f49-8848-e8df4b94df9d",
   "metadata": {},
   "source": [
    "## Part 3 - OR-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f16ed-ee77-4f36-8947-5bf617f5f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_routes(routes, customer_ids, real_durations, real_distances, service_time=30):\n",
    "    '''\n",
    "    Computes total time and distance for each route and returns a summary DataFrame.\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "\n",
    "    routes: The output of OR-tools, designated routes.\n",
    "\n",
    "    real_durations: Matrix with travel times calculated with Open Route Service.\n",
    "\n",
    "    real_distances: Matrix with travel distances calculated with Open Route Service.\n",
    "\n",
    "    service_time: Service time at each stop, default is 30 minutes.\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    \n",
    "    DataFrame with columns: vehicle_id, total_time_min, total_distance_km, num_stops\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    id_to_index = {cid: idx for idx, cid in enumerate(customer_ids)}\n",
    "    records = []\n",
    "\n",
    "    for vehicle_id, route_ids in routes.items():\n",
    "        # Time\n",
    "        total_time = 0\n",
    "        for i in range(len(route_ids) - 1):\n",
    "            from_idx = id_to_index[route_ids[i]]\n",
    "            to_idx = id_to_index[route_ids[i + 1]]\n",
    "            travel = real_durations[from_idx][to_idx]\n",
    "            stop = 0 if route_ids[i + 1] == \"RepZone\" else service_time\n",
    "            total_time += travel + stop\n",
    "\n",
    "        # Distance\n",
    "        total_distance = 0.0\n",
    "        for i in range(len(route_ids) - 1):\n",
    "            from_idx = id_to_index[route_ids[i]]\n",
    "            to_idx = id_to_index[route_ids[i + 1]]\n",
    "            dist = real_distances[from_idx][to_idx]\n",
    "            total_distance += dist\n",
    "\n",
    "        # Store summary\n",
    "        records.append({\n",
    "            \"vehicle_id\": vehicle_id,\n",
    "            \"total_time_min\": total_time,\n",
    "            \"total_distance_km\": total_distance,\n",
    "            \"num_stops\": len(route_ids) - 1  # excluding depot\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e610a4-bbd7-47b5-95dd-0d86681965e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.constraint_solver import pywrapcp, routing_enums_pb2\n",
    "\n",
    "def solve_weekly_routes_standard(real_durations,customer_ids, num_vehicles, SERVICE_TIME=30, max_work_time=480):\n",
    "    '''\n",
    "    Solves the routing problem for one cluster-week using OR-Tools.\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    \n",
    "    real_durations (np.array): Duration matrix including RepZone at index 0.\n",
    "    \n",
    "    customer_ids (list): Original customer IDs, where customer_ids[0] == 'RepZone'.\n",
    "    \n",
    "    num_vehicles (int): Number of reps * days for this schedule.\n",
    "    \n",
    "    SERVICE_TIME (int): Service time at each stop in minutes.\n",
    "    \n",
    "    max_work_time (int): Max total work time per vehicle (in minutes).\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    \n",
    "    dict: vehicle_id â†’ list of CustomerIds (route)\n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "    data = {\n",
    "        'time_matrix': real_durations.tolist(),\n",
    "        'num_vehicles': num_vehicles,\n",
    "        'depot': 0\n",
    "    }\n",
    "\n",
    "    manager = pywrapcp.RoutingIndexManager(\n",
    "        len(data['time_matrix']),\n",
    "        data['num_vehicles'],\n",
    "        [data['depot']] * data['num_vehicles'],\n",
    "        [data['depot']] * data['num_vehicles']\n",
    "    )\n",
    "\n",
    "    routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "    def total_time_callback(from_index, to_index):\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        to_node = manager.IndexToNode(to_index)\n",
    "        travel_time = data['time_matrix'][from_node][to_node]\n",
    "        service_time = 0 if from_node == 0 else SERVICE_TIME\n",
    "        return travel_time + service_time\n",
    "\n",
    "    total_time_callback_index = routing.RegisterTransitCallback(total_time_callback)\n",
    "    routing.SetArcCostEvaluatorOfAllVehicles(total_time_callback_index)\n",
    "\n",
    " \n",
    "    # Add time dimension\n",
    "    routing.AddDimension(\n",
    "        total_time_callback_index,\n",
    "        1200,              # slack\n",
    "        10000,     # hard upper bound, very large\n",
    "        True,              # start cumul at zero\n",
    "        \"Time\"\n",
    "    )\n",
    "\n",
    "    time_dimension = routing.GetDimensionOrDie(\"Time\")\n",
    "    # time_dimension.SetGlobalSpanCostCoefficient(1000)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "\n",
    "    for vehicle_id in range(num_vehicles):\n",
    "        end_index = routing.End(vehicle_id)\n",
    "        start_index = routing.Start(vehicle_id)\n",
    "\n",
    "        time_dimension.SetCumulVarSoftUpperBound(end_index, max_work_time, 100)\n",
    "        \n",
    "\n",
    "        routing.AddVariableMinimizedByFinalizer(time_dimension.CumulVar(end_index))\n",
    "        routing.AddVariableMinimizedByFinalizer(time_dimension.CumulVar(start_index))\n",
    "\n",
    "     \n",
    "\n",
    "    # Hard constraint: each customer visited once\n",
    "    penalty = 10000\n",
    "    for customer_idx in range(1, len(data['time_matrix'])):\n",
    "        routing.AddDisjunction([manager.NodeToIndex(customer_idx)], penalty)\n",
    "\n",
    "    # Loosened VisitCount dimension\n",
    "    visit_callback_index = routing.RegisterUnaryTransitCallback(lambda index: 1)\n",
    "    routing.AddDimension(\n",
    "        visit_callback_index,\n",
    "        0,                  # no slack\n",
    "        30,                 # allow many visits per rep, just soft-balance\n",
    "        True,\n",
    "        \"VisitCount\"\n",
    "    )\n",
    "    visit_dimension = routing.GetDimensionOrDie(\"VisitCount\")\n",
    "    for vehicle_id in range(num_vehicles):\n",
    "        end_index = routing.End(vehicle_id)\n",
    "        # Encourage soft upper limit of 9 visits per rep, can try in the future to make this number more dynamic\n",
    "        visit_dimension.SetCumulVarSoftUpperBound(end_index, 9, 100)\n",
    "\n",
    "\n",
    "    # Search\n",
    "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "    search_parameters.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC\n",
    "    search_parameters.local_search_metaheuristic = routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH\n",
    "    search_parameters.time_limit.seconds = 100\n",
    "\n",
    "    # Solve\n",
    "    solution = routing.SolveWithParameters(search_parameters)\n",
    "\n",
    "    if not solution:\n",
    "        print(\"No feasible solution found.\")\n",
    "        return None\n",
    "\n",
    "    routes = {}\n",
    "    new_vehicle_id = 0\n",
    "\n",
    "    for vehicle_id in range(num_vehicles):\n",
    "        index = routing.Start(vehicle_id)\n",
    "        route = []\n",
    "\n",
    "        while not routing.IsEnd(index):\n",
    "            node = manager.IndexToNode(index)\n",
    "            route.append('RepZone' if node == 0 else customer_ids[node])\n",
    "            index = solution.Value(routing.NextVar(index))\n",
    "\n",
    "        if len(route) > 1:\n",
    "            routes[new_vehicle_id] = route\n",
    "            new_vehicle_id += 1\n",
    "\n",
    "    return routes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc83f7-a9f9-4971-97c5-511c2b42349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.constraint_solver import pywrapcp, routing_enums_pb2\n",
    "\n",
    "def solve_weekly_routes_far(real_durations,customer_ids, num_vehicles, SERVICE_TIME=30, max_work_time=480):\n",
    "    '''\n",
    "    Solves the routing problem for one cluster-week using OR-Tools.\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    \n",
    "    real_durations (np.array): Duration matrix including RepZone at index 0.\n",
    "    \n",
    "    customer_ids (list): Original customer IDs, where customer_ids[0] == 'RepZone'.\n",
    "    \n",
    "    num_vehicles (int): Number of reps * days for this schedule.\n",
    "    \n",
    "    SERVICE_TIME (int): Service time at each stop in minutes.\n",
    "    \n",
    "    max_work_time (int): Max total work time per vehicle (in minutes).\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    \n",
    "    dict: vehicle_id â†’ list of CustomerIds (route)\n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "    data = {\n",
    "        'time_matrix': real_durations.tolist(),\n",
    "        'num_vehicles': num_vehicles,\n",
    "        'depot': 0\n",
    "    }\n",
    "\n",
    "    manager = pywrapcp.RoutingIndexManager(\n",
    "        len(data['time_matrix']),\n",
    "        data['num_vehicles'],\n",
    "        [data['depot']] * data['num_vehicles'],\n",
    "        [data['depot']] * data['num_vehicles']\n",
    "    )\n",
    "\n",
    "    routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "    def total_time_callback(from_index, to_index):\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        to_node = manager.IndexToNode(to_index)\n",
    "        travel_time = data['time_matrix'][from_node][to_node]\n",
    "        service_time = 0 if from_node == 0 else SERVICE_TIME\n",
    "        return travel_time + service_time\n",
    "\n",
    "    total_time_callback_index = routing.RegisterTransitCallback(total_time_callback)\n",
    "    routing.SetArcCostEvaluatorOfAllVehicles(total_time_callback_index)\n",
    "\n",
    " \n",
    "    # Add time dimension\n",
    "    routing.AddDimension(\n",
    "        total_time_callback_index,\n",
    "        1200,              # slack\n",
    "        15000,     # hard upper bound, very large\n",
    "        True,              # start cumul at zero\n",
    "        \"Time\"\n",
    "    )\n",
    "\n",
    "    time_dimension = routing.GetDimensionOrDie(\"Time\")\n",
    "    # time_dimension.SetGlobalSpanCostCoefficient(1000)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "\n",
    "    for vehicle_id in range(num_vehicles):\n",
    "        end_index = routing.End(vehicle_id)\n",
    "        start_index = routing.Start(vehicle_id)\n",
    "\n",
    "        time_dimension.SetCumulVarSoftUpperBound(end_index, max_work_time, 1000)\n",
    "        \n",
    "\n",
    "        routing.AddVariableMinimizedByFinalizer(time_dimension.CumulVar(end_index))\n",
    "        routing.AddVariableMinimizedByFinalizer(time_dimension.CumulVar(start_index))\n",
    "\n",
    "     \n",
    "\n",
    "    # Hard constraint: each customer visited once\n",
    "    penalty = 75000\n",
    "    for customer_idx in range(1, len(data['time_matrix'])):\n",
    "        routing.AddDisjunction([manager.NodeToIndex(customer_idx)], penalty)\n",
    "\n",
    "    # Loosened VisitCount dimension\n",
    "    visit_callback_index = routing.RegisterUnaryTransitCallback(lambda index: 1)\n",
    "    routing.AddDimension(\n",
    "        visit_callback_index,\n",
    "        0,                  # no slack\n",
    "        30,                 # allow many visits per rep, just soft-balance\n",
    "        True,\n",
    "        \"VisitCount\"\n",
    "    )\n",
    "    visit_dimension = routing.GetDimensionOrDie(\"VisitCount\")\n",
    "    for vehicle_id in range(num_vehicles):\n",
    "        end_index = routing.End(vehicle_id)\n",
    "        # Encourage soft upper limit of 3 visits per rep\n",
    "        visit_dimension.SetCumulVarSoftUpperBound(end_index, 3, 500)\n",
    "        visit_dimension.CumulVar(end_index).SetMax(6)\n",
    "\n",
    "\n",
    "\n",
    "    # Search\n",
    "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "    search_parameters.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC\n",
    "    search_parameters.local_search_metaheuristic = routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH\n",
    "    search_parameters.time_limit.seconds = 150\n",
    "\n",
    "    # Solve\n",
    "    solution = routing.SolveWithParameters(search_parameters)\n",
    "\n",
    "    if not solution:\n",
    "        print(\"No feasible solution found.\")\n",
    "        return None\n",
    "\n",
    "    routes = {}\n",
    "    new_vehicle_id = 0\n",
    "\n",
    "    for vehicle_id in range(num_vehicles):\n",
    "        index = routing.Start(vehicle_id)\n",
    "        route = []\n",
    "\n",
    "        while not routing.IsEnd(index):\n",
    "            node = manager.IndexToNode(index)\n",
    "            route.append('RepZone' if node == 0 else customer_ids[node])\n",
    "            index = solution.Value(routing.NextVar(index))\n",
    "\n",
    "        if len(route) > 1:\n",
    "            routes[new_vehicle_id] = route\n",
    "            new_vehicle_id += 1\n",
    "\n",
    "    return routes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3856343f-bfb0-4cd8-ba95-6d3430cc414d",
   "metadata": {},
   "source": [
    "#### Produce HTML maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc83feb-3318-4c05-902d-26c07d3f1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ors_directions(locations, profile=\"driving-car\"):\n",
    "    url = f\"http://localhost:8084/ors/v2/directions/{profile}\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    coords = [[lon, lat] for lat, lon in locations]\n",
    "\n",
    "    body = {\n",
    "        \"coordinates\": coords,\n",
    "        \"format\": \"geojson\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=body, headers=headers)\n",
    "        data = response.json()\n",
    "\n",
    "        if 'features' in data and 'geometry' in data['features'][0]:\n",
    "            road_coords = data[\"features\"][0][\"geometry\"][\"coordinates\"]\n",
    "            return [(lat, lon) for lon, lat in road_coords]\n",
    "\n",
    "        elif 'routes' in data and 'geometry' in data['routes'][0]:\n",
    "            encoded = data['routes'][0]['geometry']\n",
    "            return polyline.decode(encoded)\n",
    "\n",
    "        else:\n",
    "            print(\"Unrecognized ORS format:\", data)\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ORS parsing failed:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bca1b4-3b99-46d2-9ed2-fba4c0d027a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_routes(cluster_key, routes_all, df_schedule, df_balanced_with_centroids, repzone_offices):\n",
    "    # Extract metadata\n",
    "    parts = cluster_key.split('_')\n",
    "    cluster_id = int(parts[1])\n",
    "    week = int(parts[3])\n",
    "    routes = routes_all[cluster_key]\n",
    "\n",
    "    # Get RepZone name and lat/lon\n",
    "    repzone_name = df_balanced_with_centroids[df_balanced_with_centroids[\"cluster\"] == cluster_id][\"Assigned_RepZone\"].values[0]\n",
    "    repzone_latlon = tuple(repzone_offices[repzone_name])\n",
    "\n",
    "    # Filter schedule for that week/cluster\n",
    "    df_week = df_schedule[(df_schedule[\"week\"] == week) & (df_schedule[\"cluster\"] == cluster_id)]\n",
    "    coord_lookup = df_week.set_index(\"CustomerId\")[[\"Latitude\", \"Longitude\"]].to_dict(\"index\")\n",
    "    coord_lookup[\"RepZone\"] = {\"Latitude\": repzone_latlon[0], \"Longitude\": repzone_latlon[1]}\n",
    "\n",
    "    # Initialize map\n",
    "    m = folium.Map(location=repzone_latlon, zoom_start=10)\n",
    "    colors = get_cmap('tab20', len(routes))\n",
    "\n",
    "    # Loop through vehicles\n",
    "    for vehicle_id, route_ids in routes.items():\n",
    "        route_group = folium.FeatureGroup(name=f\"Vehicle {vehicle_id}\")\n",
    "        route_coords = []\n",
    "        # RepZone coordinates\n",
    "        repzone_coord = (coord_lookup[\"RepZone\"][\"Latitude\"], coord_lookup[\"RepZone\"][\"Longitude\"])\n",
    "        \n",
    "        # Start route with RepZone (but do NOT add marker here â€” handled globally)\n",
    "        route_coords = [repzone_coord]\n",
    "        visit_order = 0\n",
    "        \n",
    "        # Loop over remaining client IDs\n",
    "        for cid in route_ids[1:]:  # skip 'RepZone' literal\n",
    "            lat = coord_lookup[cid][\"Latitude\"]\n",
    "            lon = coord_lookup[cid][\"Longitude\"]\n",
    "            coord = (lat, lon)\n",
    "            route_coords.append(coord)\n",
    "        \n",
    "            # Plot client stop marker\n",
    "            CircleMarker(\n",
    "                location=coord,\n",
    "                radius=4,\n",
    "                color='black',\n",
    "                fill=True,\n",
    "                fill_opacity=0.8,\n",
    "                tooltip=f\"Vehicle {vehicle_id} - Stop #{visit_order} - {cid}\"\n",
    "            ).add_to(route_group)\n",
    "            visit_order += 1\n",
    "\n",
    "        if len(route_coords) > 1:\n",
    "            road_path = fetch_ors_directions(route_coords)\n",
    "            if road_path:\n",
    "                color = \"#{:02x}{:02x}{:02x}\".format(*[int(255 * c) for c in colors(int(vehicle_id) % 20)[:3]])\n",
    "                PolyLine(road_path, color=color, weight=4, tooltip=f\"Vehicle {vehicle_id}\").add_to(route_group)\n",
    "\n",
    "                Marker(\n",
    "                    location=road_path[0],\n",
    "                    popup=\"RepZone Start\",\n",
    "                    tooltip=\"RepZone Start\",\n",
    "                    icon=Icon(color='green', icon='building', prefix='fa')  # or 'home', 'flag', etc.\n",
    "                ).add_to(route_group)\n",
    "                Marker(road_path[-1], popup=\"End\", icon=Icon(color='red')).add_to(route_group)\n",
    "\n",
    "        route_group.add_to(m)\n",
    "\n",
    "    LayerControl().add_to(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7263461c-7213-4439-aa5d-a425c1e4cef3",
   "metadata": {},
   "source": [
    "## Part 4 - Compare to the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf2ac6-6320-4fef-95fc-0e238dc4c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_route_distance_OG(df_route, distance_matrix, id_to_index):\n",
    "    total_distance = 0.0\n",
    "\n",
    "    grouped = df_route.groupby(['RouteRepresentativeId', 'RouteDayOfTheWeek\\n(Mon, Tue, Wed, Thu, Fri, Sat, Sun)'])\n",
    "\n",
    "    for (rep_id, day), group in grouped:\n",
    "        group = group.sort_values(by='RouteVisitOrder')\n",
    "\n",
    "        try:\n",
    "            # Build route: start at depot (0), visit customers (no return)\n",
    "            route_indices = [0]\n",
    "            for customer_id in group['RouteCustomerId']:\n",
    "                idx = id_to_index.get(customer_id)\n",
    "                if idx is not None:\n",
    "                    route_indices.append(idx)\n",
    "                else:\n",
    "                    print(f\"Warning: CustomerId {customer_id} not found in mapping.\")\n",
    "\n",
    "            # Calculate travel distance (excluding return to depot)\n",
    "            for i in range(len(route_indices) - 1):\n",
    "                from_idx = route_indices[i]\n",
    "                to_idx = route_indices[i + 1]\n",
    "                total_distance += distance_matrix[from_idx][to_idx]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in route ({rep_id}, {day}): {e}\")\n",
    "    \n",
    "    return total_distance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
